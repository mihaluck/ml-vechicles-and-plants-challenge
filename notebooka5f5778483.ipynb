{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n    \nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:30:29.070395Z","iopub.execute_input":"2022-03-24T06:30:29.070884Z","iopub.status.idle":"2022-03-24T06:30:33.828906Z","shell.execute_reply.started":"2022-03-24T06:30:29.070798Z","shell.execute_reply":"2022-03-24T06:30:33.828117Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"__gcloud_sdk_auth__\")","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:30:33.830469Z","iopub.execute_input":"2022-03-24T06:30:33.830671Z","iopub.status.idle":"2022-03-24T06:30:34.126855Z","shell.execute_reply.started":"2022-03-24T06:30:33.830639Z","shell.execute_reply":"2022-03-24T06:30:34.126045Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:30:34.131286Z","iopub.execute_input":"2022-03-24T06:30:34.133757Z","iopub.status.idle":"2022-03-24T06:30:37.804146Z","shell.execute_reply.started":"2022-03-24T06:30:34.133711Z","shell.execute_reply":"2022-03-24T06:30:37.803428Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nGCS_PATH = KaggleDatasets().get_gcs_path()\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [45,45]\nEPOCHS = 50","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:30:37.806204Z","iopub.execute_input":"2022-03-24T06:30:37.806477Z","iopub.status.idle":"2022-03-24T06:30:38.285801Z","shell.execute_reply.started":"2022-03-24T06:30:37.806441Z","shell.execute_reply":"2022-03-24T06:30:38.285046Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"filenames = tf.io.gfile.glob(str(GCS_PATH + \"/Vehicles_vs_Plants/train/*/*.jp*g\"))\nfilenames.extend(tf.io.gfile.glob(str(GCS_PATH + \"/Vehicles_vs_Plants/train/*/*.png\")))\ntrain_filenames, val_filenames = train_test_split(filenames, test_size=0.2)\ntest_filenames = tf.io.gfile.glob(str(GCS_PATH + \"/Vehicles_vs_Plants/test/*/*.jp*g\"))\ntest_filenames.extend(tf.io.gfile.glob(str(GCS_PATH + \"/Vehicles_vs_Plants/test/*/*.png\")))","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:30:38.287095Z","iopub.execute_input":"2022-03-24T06:30:38.287575Z","iopub.status.idle":"2022-03-24T06:30:39.825421Z","shell.execute_reply.started":"2022-03-24T06:30:38.287539Z","shell.execute_reply":"2022-03-24T06:30:39.824675Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"COUNT_OTHER = len([filename for filename in train_filenames if \"Other\" in filename])\nprint(\"Other images count in training set: \" + str(COUNT_OTHER))\n\nCOUNT_PLANTS = len([filename for filename in train_filenames if \"/Plants\" in filename])\nprint(\"Plants images count in training set: \" + str(COUNT_PLANTS))\n\nCOUNT_VEHICLES = len([filename for filename in train_filenames if \"/Vehicles/\" in filename])\nprint(\"Vehicles images count in training set: \" + str(COUNT_VEHICLES))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:30:39.826612Z","iopub.execute_input":"2022-03-24T06:30:39.826867Z","iopub.status.idle":"2022-03-24T06:30:39.837114Z","shell.execute_reply.started":"2022-03-24T06:30:39.826834Z","shell.execute_reply":"2022-03-24T06:30:39.836291Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_list_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\nval_list_ds = tf.data.Dataset.from_tensor_slices(val_filenames)\n\nfor f in train_list_ds.take(5):\n    print(f.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:30:39.839470Z","iopub.execute_input":"2022-03-24T06:30:39.840012Z","iopub.status.idle":"2022-03-24T06:30:39.892678Z","shell.execute_reply.started":"2022-03-24T06:30:39.839977Z","shell.execute_reply":"2022-03-24T06:30:39.892013Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"TRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_list_ds).numpy()\nprint(\"Training images count: \" + str(TRAIN_IMG_COUNT))\n\nVAL_IMG_COUNT = tf.data.experimental.cardinality(val_list_ds).numpy()\nprint(\"Validating images count: \" + str(VAL_IMG_COUNT))","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:32:49.969547Z","iopub.execute_input":"2022-03-24T06:32:49.970089Z","iopub.status.idle":"2022-03-24T06:32:49.976841Z","shell.execute_reply.started":"2022-03-24T06:32:49.970052Z","shell.execute_reply":"2022-03-24T06:32:49.975781Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"CLASS_NAMES = np.array([str(tf.strings.split(item, os.path.sep)[-1].numpy())[2:-1]\n                        for item in tf.io.gfile.glob(str(GCS_PATH + \"/Vehicles_vs_Plants/train/*\"))])\nCLASS_NAMES","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:32:50.090772Z","iopub.execute_input":"2022-03-24T06:32:50.091075Z","iopub.status.idle":"2022-03-24T06:32:50.664954Z","shell.execute_reply.started":"2022-03-24T06:32:50.091045Z","shell.execute_reply":"2022-03-24T06:32:50.664195Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def get_label(file_path):\n    # convert the path to a list of path components\n    parts = tf.strings.split(file_path, os.path.sep)\n    # The second to last is the class-directory\n    if parts[-2] == \"Other\":\n        return 0\n    elif  parts[-2] == \"Plants\":\n        return 1\n    else:\n        return 2","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:32:50.666475Z","iopub.execute_input":"2022-03-24T06:32:50.666672Z","iopub.status.idle":"2022-03-24T06:32:50.671621Z","shell.execute_reply.started":"2022-03-24T06:32:50.666647Z","shell.execute_reply":"2022-03-24T06:32:50.670951Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def decode_img(img):\n  # convert the compressed string to a 3D uint8 tensor\n    img = tf.cond(\n    tf.image.is_jpeg(img),\n    lambda: tf.image.decode_jpeg(img, channels=3),\n    lambda: tf.image.decode_png(img, channels=3))\n  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n    img = tf.image.convert_image_dtype(img, tf.float32)\n  # resize the image to the desired size.\n    return tf.image.resize(img, IMAGE_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:32:50.672872Z","iopub.execute_input":"2022-03-24T06:32:50.673260Z","iopub.status.idle":"2022-03-24T06:32:50.681830Z","shell.execute_reply.started":"2022-03-24T06:32:50.673226Z","shell.execute_reply":"2022-03-24T06:32:50.681166Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def process_path(file_path):\n    label = get_label(file_path)\n    # load the raw data from the file as a string\n    img = tf.io.read_file(file_path)\n    img = decode_img(img)\n    return img, label","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:32:50.683641Z","iopub.execute_input":"2022-03-24T06:32:50.684297Z","iopub.status.idle":"2022-03-24T06:32:50.690712Z","shell.execute_reply.started":"2022-03-24T06:32:50.684263Z","shell.execute_reply":"2022-03-24T06:32:50.689928Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n\nval_ds = val_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:32:50.692430Z","iopub.execute_input":"2022-03-24T06:32:50.692898Z","iopub.status.idle":"2022-03-24T06:32:51.018026Z","shell.execute_reply.started":"2022-03-24T06:32:50.692862Z","shell.execute_reply":"2022-03-24T06:32:51.017339Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:33:02.892338Z","iopub.execute_input":"2022-03-24T06:33:02.892889Z","iopub.status.idle":"2022-03-24T06:33:03.672970Z","shell.execute_reply.started":"2022-03-24T06:33:02.892853Z","shell.execute_reply":"2022-03-24T06:33:03.672156Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"test_list_ds = tf.data.Dataset.list_files(str(GCS_PATH + \"/Vehicles_vs_Plants/test/*/*\"))\ntest_ds = test_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.batch(BATCH_SIZE)\nTEST_IMAGE_COUNT = tf.data.experimental.cardinality(test_list_ds).numpy()\nTEST_IMAGE_COUNT","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:33:03.676297Z","iopub.execute_input":"2022-03-24T06:33:03.676571Z","iopub.status.idle":"2022-03-24T06:33:04.157151Z","shell.execute_reply.started":"2022-03-24T06:33:03.676541Z","shell.execute_reply":"2022-03-24T06:33:04.156514Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:33:04.158539Z","iopub.execute_input":"2022-03-24T06:33:04.158788Z","iopub.status.idle":"2022-03-24T06:33:04.652515Z","shell.execute_reply.started":"2022-03-24T06:33:04.158753Z","shell.execute_reply":"2022-03-24T06:33:04.651818Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def prepare_for_training(ds, cache=True, shuffle_buffer_size=2000):\n    # This is a small dataset, only load it once, and keep it in memory.\n    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n    # fit in memory.\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n\n    # Repeat forever\n    ds = ds.repeat()\n\n    ds = ds.batch(BATCH_SIZE)\n\n    # `prefetch` lets the dataset fetch batches in the background while the model\n    # is training.\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:33:04.654625Z","iopub.execute_input":"2022-03-24T06:33:04.654874Z","iopub.status.idle":"2022-03-24T06:33:04.660257Z","shell.execute_reply.started":"2022-03-24T06:33:04.654839Z","shell.execute_reply":"2022-03-24T06:33:04.659582Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_ds = prepare_for_training(train_ds)\nval_ds = prepare_for_training(val_ds)\n\nimage_batch, label_batch = next(iter(train_ds))","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:33:04.661439Z","iopub.execute_input":"2022-03-24T06:33:04.661814Z","iopub.status.idle":"2022-03-24T06:36:14.174248Z","shell.execute_reply.started":"2022-03-24T06:33:04.661780Z","shell.execute_reply":"2022-03-24T06:36:14.172523Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def show_batch(image_batch, label_batch):\n    plt.figure(figsize=(10,10))\n    for n in range(16):\n        ax = plt.subplot(5,5,n+1)\n        plt.imshow(image_batch[n])\n        if label_batch[n] == 0:\n            plt.title(\"OTHER\")\n        elif label_batch[n] == 1:\n            plt.title(\"PLANTS\")\n        else :\n            plt.title(\"VEHICLES\")\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:36:14.175640Z","iopub.execute_input":"2022-03-24T06:36:14.175896Z","iopub.status.idle":"2022-03-24T06:36:14.182459Z","shell.execute_reply.started":"2022-03-24T06:36:14.175860Z","shell.execute_reply":"2022-03-24T06:36:14.181643Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"show_batch(image_batch.numpy(), label_batch.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-03-24T08:26:54.924526Z","iopub.execute_input":"2022-03-24T08:26:54.925079Z","iopub.status.idle":"2022-03-24T08:26:55.507049Z","shell.execute_reply.started":"2022-03-24T08:26:54.925045Z","shell.execute_reply":"2022-03-24T08:26:55.506385Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"initial_bias = np.log([COUNT_OTHER/COUNT_PLANTS])\ninitial_bias","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:36:14.829459Z","iopub.execute_input":"2022-03-24T06:36:14.829764Z","iopub.status.idle":"2022-03-24T06:36:14.837725Z","shell.execute_reply.started":"2022-03-24T06:36:14.829728Z","shell.execute_reply":"2022-03-24T06:36:14.836967Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"weight_for_0 = (1 / COUNT_OTHER)*(TRAIN_IMG_COUNT)/3.0 \nweight_for_1 = (1 / COUNT_PLANTS)*(TRAIN_IMG_COUNT)/3.0\nweight_for_2 = (1 / COUNT_VEHICLES)*(TRAIN_IMG_COUNT)/3.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))\nprint('Weight for class 2: {:.2f}'.format(weight_for_2))","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:36:14.839176Z","iopub.execute_input":"2022-03-24T06:36:14.839467Z","iopub.status.idle":"2022-03-24T06:36:14.848564Z","shell.execute_reply.started":"2022-03-24T06:36:14.839432Z","shell.execute_reply":"2022-03-24T06:36:14.847866Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\n\nmodel = keras.Sequential([\n    # Block One\n    layers.Conv2D(filters=4, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[IMAGE_SIZE[0], IMAGE_SIZE[1], 3]),\n    layers.MaxPool2D(),\n\n    # Block Two\n    layers.Conv2D(filters=8, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n#     Block Three\n    layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'),\n    layers.Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n    \n    #Dense layers\n    layers.Dropout(0.5),\n    layers.Flatten(),\n    layers.Dense(36, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(9, activation='relu'),\n    layers.Dense(3, activation='softmax'),\n])","metadata":{"execution":{"iopub.status.busy":"2022-03-24T08:23:12.003462Z","iopub.execute_input":"2022-03-24T08:23:12.004000Z","iopub.status.idle":"2022-03-24T08:23:12.088943Z","shell.execute_reply.started":"2022-03-24T08:23:12.003963Z","shell.execute_reply":"2022-03-24T08:23:12.087735Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"model.compile(\n        optimizer='adam',\n        loss='sparse_categorical_crossentropy',\n        metrics='sparse_categorical_accuracy'\n    )","metadata":{"execution":{"iopub.status.busy":"2022-03-24T08:23:14.462591Z","iopub.execute_input":"2022-03-24T08:23:14.462846Z","iopub.status.idle":"2022-03-24T08:23:14.473059Z","shell.execute_reply.started":"2022-03-24T08:23:14.462818Z","shell.execute_reply":"2022-03-24T08:23:14.472205Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    steps_per_epoch=TRAIN_IMG_COUNT // (BATCH_SIZE),\n    epochs=100,\n    validation_data=val_ds,\n    validation_steps=VAL_IMG_COUNT // (BATCH_SIZE),\n    class_weight=class_weight,\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T08:23:16.335442Z","iopub.execute_input":"2022-03-24T08:23:16.335893Z","iopub.status.idle":"2022-03-24T08:23:57.770954Z","shell.execute_reply.started":"2022-03-24T08:23:16.335858Z","shell.execute_reply":"2022-03-24T08:23:57.770178Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['sparse_categorical_accuracy', 'val_sparse_categorical_accuracy']].plot();","metadata":{"execution":{"iopub.status.busy":"2022-03-24T08:25:08.369333Z","iopub.execute_input":"2022-03-24T08:25:08.370055Z","iopub.status.idle":"2022-03-24T08:25:08.739884Z","shell.execute_reply.started":"2022-03-24T08:25:08.370019Z","shell.execute_reply":"2022-03-24T08:25:08.739221Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(test_ds)\npredictions = np.argmax(pred, axis=-1)\nprobability = np.max(pred, axis=-1)\nlabels = {1:'Plants',2:'Vehicles'}\nlen([print(test_filenames[i].split('/')[-1], probability[i], labels[predictions[i]]) for i, v in enumerate(predictions.tolist()) if predictions[i] == 1 or predictions[i] == 2])","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:38:39.675259Z","iopub.execute_input":"2022-03-24T06:38:39.675467Z","iopub.status.idle":"2022-03-24T06:42:09.747892Z","shell.execute_reply.started":"2022-03-24T06:38:39.675443Z","shell.execute_reply":"2022-03-24T06:42:09.747217Z"},"trusted":true},"execution_count":36,"outputs":[]}]}